{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import itertools\n",
    "import gtsam\n",
    "import gtsam.utils.plot\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def main():\n",
    " \n",
    "    # Set default figure size\n",
    "    plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "    \n",
    "    # Directory containing the 6 images\n",
    "    image_dir = '/home/kasturi/AFR_EECE7150/HW3/tape018'  # Update this path to your images directory\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 1. Load Images and Camera Matrix\n",
    "    # -----------------------------\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for filename in sorted(os.listdir(image_dir)):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is not None:\n",
    "            # Normalize image intensity to range [0, 255]\n",
    "            cv2.normalize(image, image, 0, 255, cv2.NORM_MINMAX)\n",
    "            images.append(image)\n",
    "    \n",
    "    if not images:\n",
    "        raise ValueError(\"No images found in the specified directory.\")\n",
    "    \n",
    "    image_height, image_width = images[0].shape[:2]\n",
    "    \n",
    "    # Define approximate camera matrix (intrinsic parameters)\n",
    "    camera_matrix = np.array([\n",
    "        [1, 0, image_width / 2],\n",
    "        [0, 1, image_height / 2],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 2. Non-Maximum Suppression\n",
    "    # -----------------------------\n",
    "    \n",
    "    def compute_nms_mask(keypoints, image_shape, radius=2):\n",
    "        \"\"\"\n",
    "        Compute Non-Maximum Suppression mask for keypoints.\n",
    "        Retains keypoints with the highest response within a local neighborhood.\n",
    "        \"\"\"\n",
    "        binary_image = np.zeros(image_shape, dtype=np.uint8)\n",
    "        responses = np.array([kp.response for kp in keypoints])\n",
    "        sorted_indices = np.flip(np.argsort(responses))\n",
    "        nms_mask = []\n",
    "        for idx in sorted_indices:\n",
    "            x, y = int(round(keypoints[idx].pt[0])), int(round(keypoints[idx].pt[1]))\n",
    "            if binary_image[y, x] == 0:\n",
    "                nms_mask.append(idx)\n",
    "                # Suppress neighbors within the specified radius\n",
    "                cv2.circle(binary_image, (x, y), radius, 255, -1)\n",
    "        return nms_mask\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 3. Keypoint Normalization\n",
    "    # -----------------------------\n",
    "    \n",
    "    def normalize_keypoints(keypoints, camera_matrix):\n",
    "        \"\"\"\n",
    "        Normalize keypoints using the inverse camera matrix.\n",
    "        \"\"\"\n",
    "        inv_K = np.linalg.inv(camera_matrix)\n",
    "        for kp in keypoints:\n",
    "            pt_homogeneous = np.array([kp.pt[0], kp.pt[1], 1.0])\n",
    "            normalized_pt = inv_K @ pt_homogeneous\n",
    "            kp.pt = tuple(normalized_pt[:-1])\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 4. Compute SIFT Features and Visualize Keypoints\n",
    "    # -----------------------------\n",
    "    \n",
    "    sift = cv2.SIFT_create(\n",
    "        nfeatures=4000,\n",
    "        nOctaveLayers=12,\n",
    "        contrastThreshold=0.025,\n",
    "        sigma=1.5\n",
    "    )\n",
    "    keypoints_list = []\n",
    "    descriptors_list = []\n",
    "    \n",
    "    for idx, image in enumerate(images):\n",
    "        keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "        \n",
    "        # Apply Non-Maximum Suppression\n",
    "        nms_mask = compute_nms_mask(keypoints, image.shape)\n",
    "        keypoints = [keypoints[i] for i in nms_mask]\n",
    "        if descriptors is not None:\n",
    "            descriptors = descriptors[nms_mask]\n",
    "        else:\n",
    "            descriptors = np.array([])  \n",
    "            \n",
    "        # Limit the number of keypoints to the top 500 based on response\n",
    "        keypoints = keypoints[:700]\n",
    "        descriptors = descriptors[:700]\n",
    "\n",
    "        \n",
    "        # Visualize Keypoints before Normalization\n",
    "        img_kp = cv2.drawKeypoints(\n",
    "            image, keypoints, None,\n",
    "            flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "        )\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(img_kp, cmap='gray')\n",
    "        plt.title(f'Image {idx} Keypoints before Normalization')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Normalize Keypoints\n",
    "        normalize_keypoints(keypoints, camera_matrix)\n",
    "        \n",
    "        keypoints_list.append(keypoints)\n",
    "        descriptors_list.append(descriptors)\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 5. Feature Matching\n",
    "    # -----------------------------\n",
    "    \n",
    "    bf_matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    \n",
    "    def match_keypoints(src_kp, src_desc, dst_kp, dst_desc, ratio=0.75):\n",
    "        \"\"\"\n",
    "        Match keypoints between two images using BFMatcher and Lowe's ratio test.\n",
    "        \"\"\"\n",
    "        if len(src_desc) == 0 or len(dst_desc) == 0:\n",
    "            return np.array([]), np.array([]), []\n",
    "        \n",
    "        # Perform KNN matching \n",
    "        matches = bf_matcher.knnMatch(src_desc, dst_desc, k=2)\n",
    "        \n",
    "        # Apply Lowe's ratio test\n",
    "        good_matches = []\n",
    "        src_pts = []\n",
    "        dst_pts = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < ratio * n.distance:\n",
    "                good_matches.append(m)\n",
    "                src_pts.append(src_kp[m.queryIdx].pt)\n",
    "                dst_pts.append(dst_kp[m.trainIdx].pt)\n",
    "        return np.array(src_pts), np.array(dst_pts), good_matches\n",
    "   \n",
    "    # -----------------------------\n",
    "    # 6. Pose Initialization and Noise Models\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Prior noise model for the first pose\n",
    "    prior_noise = gtsam.noiseModel.Diagonal.Sigmas(\n",
    "        np.array([10, 10, np.deg2rad(10)])  # [x, y, theta]\n",
    "    )\n",
    "    \n",
    "    # Initialize GTSAM Values and Covariance dictionary\n",
    "    initial_estimates = gtsam.Values()\n",
    "    initial_covariances = {}  # To store initial covariances\n",
    "    \n",
    "    def estimate_affine_transform(src_pts, dst_pts, check=False):\n",
    "        \"\"\"\n",
    "        Estimate affine transformation and compute noise model.\n",
    "        Returns the inverse affine matrix and noise model.\n",
    "        \"\"\"\n",
    "        if len(src_pts) < 3:\n",
    "            return None  # Not enough points to estimate affine transform\n",
    "        affine_mat, mask = cv2.estimateAffinePartial2D(src_pts, dst_pts)\n",
    "        if affine_mat is None:\n",
    "            return None\n",
    "        match_count = np.count_nonzero(mask)\n",
    "        if check and match_count < 3:\n",
    "            return None\n",
    "        # Normalize affine matrix to remove scale\n",
    "        scale = np.sqrt(affine_mat[0, 0] ** 2 + affine_mat[1, 0] ** 2)\n",
    "        if scale == 0:\n",
    "            return None\n",
    "        affine_mat[:2, :2] /= scale\n",
    "        # Define covariance based on match count\n",
    "        diag_noise = 1000 * (match_count ** -2) * np.array([1, 1, np.deg2rad(1)])\n",
    "        noise_model = gtsam.noiseModel.Diagonal.Sigmas(diag_noise)\n",
    "        # Convert to homogeneous affine matrix\n",
    "        affine_mat_homogeneous = np.vstack((affine_mat, [0, 0, 1]))\n",
    "        return np.linalg.inv(affine_mat_homogeneous), noise_model\n",
    "    \n",
    "    def affine_to_pose2(affine_mat):\n",
    "        \"\"\"\n",
    "        Convert affine transformation matrix to gtsam.Pose2.\n",
    "        \"\"\"\n",
    "        x = affine_mat[0, -1]\n",
    "        y = affine_mat[1, -1]\n",
    "        theta = np.arctan2(affine_mat[1, 0], affine_mat[0, 0])\n",
    "        return gtsam.Pose2(x, y, theta)\n",
    "    \n",
    "    # Initialize the first pose as the origin\n",
    "    initial_estimates.insert(0, gtsam.Pose2())\n",
    "    initial_covariances[0] = np.diag(prior_noise.sigmas() ** 2)  # Prior covariance for the first pose\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 7. Initializing Poses and Visualizing Matches\n",
    "    # -----------------------------\n",
    "    \n",
    "    match_cache = {}\n",
    "    total_affine = np.eye(3)  # Initialize cumulative affine transform\n",
    "    \n",
    "    def get_matching_points(src_idx, dst_idx, visualize=True):\n",
    "        \"\"\"\n",
    "        Retrieve or compute matching points between image pairs and visualize matches.\n",
    "        Caches the result to avoid redundant computations.\n",
    "        \"\"\"\n",
    "        if (src_idx, dst_idx) in match_cache:\n",
    "            return match_cache[(src_idx, dst_idx)]\n",
    "        else:\n",
    "            src_kp = keypoints_list[src_idx]\n",
    "            src_desc = descriptors_list[src_idx]\n",
    "            dst_kp = keypoints_list[dst_idx]\n",
    "            dst_desc = descriptors_list[dst_idx]\n",
    "            src_pts, dst_pts, good_matches = match_keypoints(src_kp, src_desc, dst_kp, dst_desc)\n",
    "            \n",
    "            if visualize and len(good_matches) > 0:\n",
    "                # Visualize Matches\n",
    "                img_matches = cv2.drawMatches(\n",
    "                    images[src_idx], src_kp,\n",
    "                    images[dst_idx], dst_kp,\n",
    "                    good_matches, None,\n",
    "                    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "                )\n",
    "                plt.figure(figsize=(15, 8))\n",
    "                plt.imshow(img_matches)\n",
    "                plt.title(f'Feature Matches between Image {src_idx} and Image {dst_idx}')\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            match_cache[(src_idx, dst_idx)] = (src_pts, dst_pts)\n",
    "            return src_pts, dst_pts\n",
    "    \n",
    "    # Initialize poses for sequential pairs\n",
    "    for i in range(len(images) - 1):\n",
    "        j = i + 1\n",
    "        src_pts, dst_pts = get_matching_points(i, j)\n",
    "        result = estimate_affine_transform(src_pts, dst_pts)\n",
    "        if result is not None:\n",
    "            affine_mat, noise_model = result\n",
    "            total_affine = affine_mat @ total_affine  # Update cumulative affine transform\n",
    "            pose = affine_to_pose2(total_affine)\n",
    "            initial_estimates.insert(j, pose)\n",
    "            # Convert noise_model to covariance matrix\n",
    "            sigmas = noise_model.sigmas()\n",
    "            cov_matrix = np.diag(sigmas ** 2)\n",
    "            initial_covariances[j] = cov_matrix\n",
    "        else:\n",
    "            # If no good match, use identity transformation with high uncertainty\n",
    "            initial_estimates.insert(j, gtsam.Pose2())\n",
    "            initial_covariances[j] = np.diag(np.array([1e12, 1e12, (1e6)**2]))\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 8. Overlap Check\n",
    "    # -----------------------------\n",
    "    \n",
    "    def has_overlap(pose1, pose2, threshold=None):\n",
    "        \"\"\"\n",
    "        Check if two poses have overlap based on their translations.\n",
    "        Uses the image width as a default threshold if none provided.\n",
    "        \"\"\"\n",
    "        if threshold is None:\n",
    "            threshold = image_width  # Default threshold based on image width\n",
    "        distance = np.linalg.norm(np.array([pose1.x(), pose1.y()]) - np.array([pose2.x(), pose2.y()]))\n",
    "        return distance < threshold\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 9. Building the Pose Graph\n",
    "    # -----------------------------\n",
    "    \n",
    "    def construct_pose_graph(values):\n",
    "        \"\"\"\n",
    "        Build the pose graph for optimization.\n",
    "        Adds prior and between factors based on feature matches.\n",
    "        \"\"\"\n",
    "        graph = gtsam.NonlinearFactorGraph()\n",
    "        # Add prior factor for the first pose\n",
    "        graph.add(gtsam.PriorFactorPose2(0, values.atPose2(0), prior_noise))\n",
    "        \n",
    "        # Iterate over all possible image pairs\n",
    "        for i, j in itertools.combinations(range(len(images)), 2):\n",
    "            if i + 1 == j:\n",
    "                # Sequential pair (odometry)\n",
    "                src_pts, dst_pts = get_matching_points(i, j, visualize=False)\n",
    "                result = estimate_affine_transform(src_pts, dst_pts)\n",
    "                if result is not None:\n",
    "                    affine_mat, noise_model = result\n",
    "                    pose_between = affine_to_pose2(affine_mat)\n",
    "                    graph.add(gtsam.BetweenFactorPose2(i, j, pose_between, noise_model))\n",
    "            elif has_overlap(values.atPose2(i), values.atPose2(j)):\n",
    "                # Loop closure pair\n",
    "                src_pts, dst_pts = get_matching_points(i, j, visualize=False)\n",
    "                result = estimate_affine_transform(src_pts, dst_pts, check=True)\n",
    "                if result is not None:\n",
    "                    affine_mat, noise_model = result\n",
    "                    pose_between = affine_to_pose2(affine_mat)\n",
    "                    graph.add(gtsam.BetweenFactorPose2(i, j, pose_between, noise_model))\n",
    "        return graph\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 10. Visualizing the Pose Graph\n",
    "    # -----------------------------\n",
    "    \n",
    "    def visualize_pose_graph(values, graph, marginals, title='Optimized Poses and Pose Graph'):\n",
    "        \"\"\"\n",
    "        Visualize the poses and pose graph connections with covariance ellipses.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        # Plot poses and covariance ellipses\n",
    "        for i in range(values.size()):\n",
    "            pose = values.atPose2(i)\n",
    "            covariance = marginals.marginalCovariance(i)\n",
    "            mu_x, mu_y, theta = pose.x(), pose.y(), pose.theta()\n",
    "            \n",
    "            # Plot pose arrow\n",
    "            dx = np.cos(theta) * 10  # Scale arrow length for better visibility\n",
    "            dy = np.sin(theta) * 10\n",
    "            ax.arrow(mu_x, mu_y, dx, dy, head_width=5, head_length=5, fc='k', ec='k')\n",
    "            \n",
    "            # Plot covariance ellipse\n",
    "            cov = covariance[:2, :2]\n",
    "            eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "            angle = np.degrees(np.arctan2(eigvecs[1, 0], eigvecs[0, 0]))\n",
    "            width, height = 2 * np.sqrt(eigvals)  # 1-sigma ellipse\n",
    "            ellipse = Ellipse(\n",
    "                (mu_x, mu_y), width, height, angle=angle,\n",
    "                edgecolor='blue', facecolor='none', linestyle='--'\n",
    "            )\n",
    "            ax.add_patch(ellipse)\n",
    "        \n",
    "        # Plot edges\n",
    "        for idx in range(graph.size()):\n",
    "            factor = graph.at(idx)\n",
    "            if isinstance(factor, gtsam.BetweenFactorPose2):\n",
    "                keys = factor.keys()\n",
    "                key1, key2 = keys[0], keys[1]\n",
    "                pose1 = values.atPose2(key1)\n",
    "                pose2 = values.atPose2(key2)\n",
    "                ax.plot([pose1.x(), pose2.x()], [pose1.y(), pose2.y()], 'k-', alpha=0.5)\n",
    "        \n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "        ax.set_title(title)\n",
    "        ax.axis('equal')\n",
    "        plt.show()\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 11. Plotting Initial vs. Optimized Poses\n",
    "    # -----------------------------\n",
    "    \n",
    "    def plot_initial_vs_optimized(initial_values, optimized_values, marginals_initial, marginals_optimized):\n",
    "        \"\"\"\n",
    "        Plot initial and optimized poses with covariance ellipses.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        # Plot initial poses\n",
    "        for i in range(initial_values.size()):\n",
    "            pose = initial_values.atPose2(i)\n",
    "            covariance = marginals_initial.marginalCovariance(i)\n",
    "            mu_x, mu_y, theta = pose.x(), pose.y(), pose.theta()\n",
    "            \n",
    "            # Plot initial pose arrow\n",
    "            dx = np.cos(theta) * 10\n",
    "            dy = np.sin(theta) * 10\n",
    "            ax.arrow(mu_x, mu_y, dx, dy, head_width=5, head_length=5, fc='blue', ec='blue', label='Initial Pose' if i == 0 else \"\")\n",
    "            \n",
    "            # Plot initial covariance ellipse\n",
    "            cov = covariance[:2, :2]\n",
    "            eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "            angle = np.degrees(np.arctan2(eigvecs[1, 0], eigvecs[0, 0]))\n",
    "            width, height = 2 * np.sqrt(eigvals)  # 1-sigma ellipse\n",
    "            ellipse = Ellipse(\n",
    "                (mu_x, mu_y), width, height, angle=angle,\n",
    "                edgecolor='blue', facecolor='none', linestyle='--'\n",
    "            )\n",
    "            ax.add_patch(ellipse)\n",
    "        \n",
    "        # Plot optimized poses\n",
    "        for i in range(optimized_values.size()):\n",
    "            pose = optimized_values.atPose2(i)\n",
    "            covariance = marginals_optimized.marginalCovariance(i)\n",
    "            mu_x, mu_y, theta = pose.x(), pose.y(), pose.theta()\n",
    "            \n",
    "            # Plot optimized pose arrow\n",
    "            dx = np.cos(theta) * 10\n",
    "            dy = np.sin(theta) * 10\n",
    "            ax.arrow(mu_x, mu_y, dx, dy, head_width=5, head_length=5, fc='red', ec='red', label='Optimized Pose' if i == 0 else \"\")\n",
    "            \n",
    "            # Plot optimized covariance ellipse\n",
    "            cov = covariance[:2, :2]\n",
    "            eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "            angle = np.degrees(np.arctan2(eigvecs[1, 0], eigvecs[0, 0]))\n",
    "            width, height = 2 * np.sqrt(eigvals)  # 1-sigma ellipse\n",
    "            ellipse = Ellipse(\n",
    "                (mu_x, mu_y), width, height, angle=angle,\n",
    "                edgecolor='red', facecolor='none', linestyle='--'\n",
    "            )\n",
    "            ax.add_patch(ellipse)\n",
    "        \n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "        ax.set_title('Initial (Blue) vs. Optimized (Red) Poses with Covariances')\n",
    "        ax.axis('equal')\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        ax.legend(by_label.values(), by_label.keys())\n",
    "        plt.show()\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 12. Plotting Covariances Before and After Optimization\n",
    "    # -----------------------------\n",
    "    \n",
    "    def plot_covariances(initial_covariances, marginals_optimized, optimized_values):\n",
    "        \"\"\"\n",
    "        Plot covariance ellipses before and after optimization for each pose.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            # Initial covariance\n",
    "            pose_initial = initial_estimates.atPose2(i)\n",
    "            cov_initial = initial_covariances.get(i, np.eye(3))\n",
    "            cov_initial = cov_initial[:2, :2]\n",
    "            \n",
    "            # Plot initial covariance ellipse\n",
    "            eigvals, eigvecs = np.linalg.eigh(cov_initial)\n",
    "            angle = np.degrees(np.arctan2(eigvecs[1, 0], eigvecs[0, 0]))\n",
    "            width, height = 2 * np.sqrt(eigvals)\n",
    "            ellipse_initial = Ellipse(\n",
    "                (pose_initial.x(), pose_initial.y()), width, height, angle=angle,\n",
    "                edgecolor='blue', facecolor='none', linestyle='--', label='Initial Covariance' if i == 0 else \"\"\n",
    "            )\n",
    "            ax.add_patch(ellipse_initial)\n",
    "            \n",
    "            # Optimized covariance\n",
    "            pose_optimized = optimized_values.atPose2(i)\n",
    "            cov_optimized = marginals_optimized.marginalCovariance(i)[:2, :2]\n",
    "            \n",
    "            # Plot optimized covariance ellipse\n",
    "            eigvals, eigvecs = np.linalg.eigh(cov_optimized)\n",
    "            angle = np.degrees(np.arctan2(eigvecs[1, 0], eigvecs[0, 0]))\n",
    "            width, height = 2 * np.sqrt(eigvals)\n",
    "            ellipse_optimized = Ellipse(\n",
    "                (pose_optimized.x(), pose_optimized.y()), width, height, angle=angle,\n",
    "                edgecolor='red', facecolor='none', linestyle='--', label='Optimized Covariance' if i == 0 else \"\"\n",
    "            )\n",
    "            ax.add_patch(ellipse_optimized)\n",
    "        \n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "        ax.set_title('Covariance Before (Blue) and After (Red) Optimization')\n",
    "        ax.axis('equal')\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        ax.legend(by_label.values(), by_label.keys())\n",
    "        plt.show()\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 13. Optimizing the Pose Graph\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Construct the pose graph\n",
    "    graph = construct_pose_graph(initial_estimates)\n",
    "    \n",
    "    # Compute initial marginals before optimization\n",
    "    marginals_initial = gtsam.Marginals(graph, initial_estimates)\n",
    "    \n",
    "    # Optimize the pose graph\n",
    "    params = gtsam.LevenbergMarquardtParams()\n",
    "    optimizer = gtsam.LevenbergMarquardtOptimizer(graph, initial_estimates, params)\n",
    "    result = optimizer.optimize()\n",
    "    marginals_optimized = gtsam.Marginals(graph, result)\n",
    "    \n",
    "    # Visualize the optimized pose graph\n",
    "    visualize_pose_graph(result, graph, marginals_optimized, title='Optimized Poses and Pose Graph')\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 14. Plotting Initial vs. Optimized Poses\n",
    "    # -----------------------------\n",
    "    \n",
    "    plot_initial_vs_optimized(initial_estimates, result, marginals_initial, marginals_optimized)\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 15. Plotting Covariances Before and After Optimization\n",
    "    # -----------------------------\n",
    "    \n",
    "    plot_covariances(initial_covariances, marginals_optimized, result)\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 16. Extracting Optimized Poses\n",
    "    # -----------------------------\n",
    "    \n",
    "    poses = gtsam.utilities.allPose2s(result)\n",
    "    affine_matrices = []\n",
    "    \n",
    "    for idx in range(len(images)):\n",
    "        pose = poses.atPose2(idx)\n",
    "        affine_mat = pose.matrix()\n",
    "        translation = np.eye(3)\n",
    "        translation[:2, 2] -= np.array([image_width / 2, image_height / 2])\n",
    "        affine_matrices.append(affine_mat @ translation)\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 17. Computing the Stitching Area\n",
    "    # -----------------------------\n",
    "    \n",
    "    def apply_homography(point, homography):\n",
    "        \"\"\"\n",
    "        Apply homography to a 2D point.\n",
    "        \"\"\"\n",
    "        point_homogeneous = np.array([point[0], point[1], 1.0])\n",
    "        transformed_point = homography @ point_homogeneous\n",
    "        return (transformed_point / transformed_point[2])[:2]\n",
    "    \n",
    "    def compute_stitching_area(homographies, image_width, image_height):\n",
    "        \"\"\"\n",
    "        Compute the size and offset for the stitched image.\n",
    "        \"\"\"\n",
    "        corner_points = []\n",
    "        for H in homographies:\n",
    "            corners = [\n",
    "                [0, 0],\n",
    "                [image_width - 1, 0],\n",
    "                [image_width - 1, image_height - 1],\n",
    "                [0, image_height - 1]\n",
    "            ]\n",
    "            for corner in corners:\n",
    "                transformed_corner = apply_homography(corner, H)\n",
    "                corner_points.append(transformed_corner)\n",
    "        \n",
    "        corner_points = np.array(corner_points)\n",
    "        min_point = np.floor(np.min(corner_points, axis=0)).astype(int)\n",
    "        max_point = np.ceil(np.max(corner_points, axis=0)).astype(int)\n",
    "        \n",
    "        size = (max_point - min_point + 1).astype(int)\n",
    "        offset = np.eye(3)\n",
    "        offset[0, 2] -= min_point[0]\n",
    "        offset[1, 2] -= min_point[1]\n",
    "        return tuple(size), offset\n",
    "    \n",
    "    stitch_size, offset_matrix = compute_stitching_area(affine_matrices, image_width, image_height)\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 18. Stitching the Images\n",
    "    # -----------------------------\n",
    "    \n",
    "    def stitch_images(homographies, images, size, offset):\n",
    "        \"\"\"\n",
    "        Warp and blend images to create the final stitched image.\n",
    "        \"\"\"\n",
    "        stitched_image = np.zeros((size[1], size[0]), dtype=np.uint8)\n",
    "        \n",
    "        for H, img in zip(homographies, images):\n",
    "            warp_mat = offset @ H\n",
    "            warped_img = cv2.warpPerspective(img, warp_mat, (size[0], size[1]))\n",
    "            mask = (warped_img > 0)\n",
    "            # Blend images by overlaying\n",
    "            stitched_image[mask] = warped_img[mask]\n",
    "        return stitched_image\n",
    "    \n",
    "    stitched_image = stitch_images(affine_matrices, images, stitch_size, offset_matrix)\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 19. Displaying the Stitched Image\n",
    "    # -----------------------------\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(stitched_image, cmap='gray')\n",
    "    plt.title('Final Stitched Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Optionally, save the stitched image\n",
    "    cv2.imwrite('stitched_image_GTSAM.png', stitched_image)\n",
    "\n",
    "# -----------------------------\n",
    "# Run the Main Function\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
